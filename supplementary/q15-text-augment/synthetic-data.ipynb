{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rickiepark/MLQandAI/blob/main/supplementary/q15-text-augment/synthetic-data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "31ae3a94-7cae-40c5-b494-68ea023bf681",
      "metadata": {
        "id": "31ae3a94-7cae-40c5-b494-68ea023bf681"
      },
      "source": [
        "## 디코더 기반 LLM을 사용해 데이터 증식을 위한 합성 데이터 생성하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "51461d61-1d5c-4b26-ad8f-053b46b2a545",
      "metadata": {
        "id": "51461d61-1d5c-4b26-ad8f-053b46b2a545",
        "outputId": "b99ec1d2-6824-49c0-af10-509299133e4d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: watermark in /usr/local/lib/python3.10/dist-packages (2.4.3)\n",
            "Requirement already satisfied: ipython>=6.0 in /usr/local/lib/python3.10/dist-packages (from watermark) (7.34.0)\n",
            "Requirement already satisfied: importlib-metadata>=1.4 in /usr/local/lib/python3.10/dist-packages (from watermark) (8.5.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from watermark) (71.0.4)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=1.4->watermark) (3.20.1)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.0->watermark) (0.19.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=6.0->watermark) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=6.0->watermark) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.0->watermark) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.0->watermark) (3.0.47)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=6.0->watermark) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=6.0->watermark) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=6.0->watermark) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.0->watermark) (4.9.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=6.0->watermark) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=6.0->watermark) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.0->watermark) (0.2.13)\n",
            "Author: Sebastian Raschka\n",
            "\n",
            "Python implementation: CPython\n",
            "Python version       : 3.10.12\n",
            "IPython version      : 7.34.0\n",
            "\n",
            "transformers: 4.44.2\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!pip install watermark\n",
        "\n",
        "%load_ext watermark\n",
        "%watermark -a 'Sebastian Raschka' -v -p transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "bd8f113d-56c5-492b-ac07-2105169c7f15",
      "metadata": {
        "id": "bd8f113d-56c5-492b-ac07-2105169c7f15"
      },
      "outputs": [],
      "source": [
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "\n",
        "\n",
        "def generate_synthetic_text(prompt, num_samples=1):\n",
        "    model_name = \"gpt2\"\n",
        "    model = GPT2LMHeadModel.from_pretrained(model_name)\n",
        "    tokenizer = GPT2Tokenizer.from_pretrained(model_name,\n",
        "                                              clean_up_tokenization_spaces=False)\n",
        "\n",
        "    synthetic_texts = []\n",
        "    for _ in range(num_samples):\n",
        "        inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "        input_ids = inputs[\"input_ids\"]\n",
        "        attention_mask = inputs[\"attention_mask\"]\n",
        "\n",
        "        sample_output = model.generate(\n",
        "            input_ids,\n",
        "            max_length=100,  # 생성될 텍스트의 최대 길이\n",
        "            min_length=30,   # 생성될 텍스트의 최소 길이\n",
        "            num_return_sequences=1,\n",
        "            attention_mask=attention_mask,\n",
        "            no_repeat_ngram_size=2 # n-그램(여기서는 2-그램)의 반복을 막기 위해\n",
        "        )\n",
        "\n",
        "        text = tokenizer.decode(sample_output[0], skip_special_tokens=True)\n",
        "        synthetic_texts.append(text)\n",
        "\n",
        "    return synthetic_texts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "2333612b-7fe3-4c38-9608-09945df78bcd",
      "metadata": {
        "id": "2333612b-7fe3-4c38-9608-09945df78bcd",
        "outputId": "0a3a5f1b-d4df-4f10-b3ae-4fefbc853d74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The weather was nice and I enjoyed the view. I was able to get a good view of the city and the surrounding area. The weather is good and it was a nice day.\n",
            "\n",
            "I was very impressed with the views. It was the first time I've been to the area and was really impressed. We had a great time and we were able get to see the entire city. There was also a lot of parking and there was plenty of traffic. Parking is very easy and you can\n"
          ]
        }
      ],
      "source": [
        "# 프롬프트\n",
        "prompt = \"The weather was nice and I enjoyed\"\n",
        "\n",
        "# 합성 데이터 생성하기\n",
        "synthetic_data = generate_synthetic_text(prompt)\n",
        "for text in synthetic_data:\n",
        "    print(text)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}