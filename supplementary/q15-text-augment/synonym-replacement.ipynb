{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rickiepark/MLQandAI/blob/main/supplementary/q15-text-augment/synonym-replacement.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b050edae-48cf-47ba-b2ae-bf9fc9098bb4",
      "metadata": {
        "id": "b050edae-48cf-47ba-b2ae-bf9fc9098bb4"
      },
      "source": [
        "## 텍스트 증식을 위한 동의어 교체"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "0ab61d1f-466f-4469-99da-b172a959c2cb",
      "metadata": {
        "id": "0ab61d1f-466f-4469-99da-b172a959c2cb",
        "outputId": "131876a6-dc03-4636-caa4-e839ca90e1b8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: watermark in /usr/local/lib/python3.10/dist-packages (2.4.3)\n",
            "Requirement already satisfied: ipython>=6.0 in /usr/local/lib/python3.10/dist-packages (from watermark) (7.34.0)\n",
            "Requirement already satisfied: importlib-metadata>=1.4 in /usr/local/lib/python3.10/dist-packages (from watermark) (8.5.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from watermark) (71.0.4)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=1.4->watermark) (3.20.1)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.0->watermark) (0.19.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=6.0->watermark) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=6.0->watermark) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.0->watermark) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.0->watermark) (3.0.47)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=6.0->watermark) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=6.0->watermark) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=6.0->watermark) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.0->watermark) (4.9.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=6.0->watermark) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=6.0->watermark) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.0->watermark) (0.2.13)\n",
            "Author: Sebastian Raschka\n",
            "\n",
            "Python implementation: CPython\n",
            "Python version       : 3.10.12\n",
            "IPython version      : 7.34.0\n",
            "\n",
            "nltk: 3.8.1\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!pip install watermark\n",
        "\n",
        "%load_ext watermark\n",
        "%watermark -a 'Sebastian Raschka' -v -p nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "2e4539cb-2c81-47e2-8be9-03206f750771",
      "metadata": {
        "id": "2e4539cb-2c81-47e2-8be9-03206f750771",
        "outputId": "d202e300-572d-4531-91ab-18094ab87b16",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import nltk\n",
        "\n",
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "81874f62-821b-40b3-94a0-f22e45d82352",
      "metadata": {
        "id": "81874f62-821b-40b3-94a0-f22e45d82352",
        "outputId": "fb3aa60c-14d9-41a0-9e26-0745fce43204",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['quickly',\n",
              " 'rapidly',\n",
              " 'speedily',\n",
              " 'chop-chop',\n",
              " 'apace',\n",
              " 'promptly',\n",
              " 'quickly',\n",
              " 'quick',\n",
              " 'cursorily',\n",
              " 'quickly']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "from nltk.corpus import wordnet\n",
        "\n",
        "nltk.download('wordnet')\n",
        "\n",
        "def get_synonyms(word):\n",
        "    synonyms = []\n",
        "    for syn in wordnet.synsets(word):\n",
        "        for lemma in syn.lemmas():\n",
        "            synonyms.append(lemma.name())\n",
        "    return synonyms\n",
        "\n",
        "\n",
        "get_synonyms(\"quickly\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "6987216a-2485-4494-8d0f-45f5feffe5dd",
      "metadata": {
        "id": "6987216a-2485-4494-8d0f-45f5feffe5dd",
        "outputId": "150e735d-e6c9-4f91-d855-8cb51845e31a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# 품사 태깅을 위해\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "85d75f89-11dd-4248-b005-4c08981aa79b",
      "metadata": {
        "id": "85d75f89-11dd-4248-b005-4c08981aa79b",
        "outputId": "d61a2eee-5af7-41d8-b6bc-318906a3ec31",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('The', 'DT'),\n",
              " ('cat', 'NN'),\n",
              " ('quickly', 'RB'),\n",
              " ('jumped', 'VBD'),\n",
              " ('over', 'IN'),\n",
              " ('the', 'DT'),\n",
              " ('lazy', 'JJ'),\n",
              " ('dog', 'NN'),\n",
              " ('.', '.')]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "def get_position_tags(text):\n",
        "    words = nltk.word_tokenize(text)\n",
        "    pos_tags = nltk.pos_tag(words)\n",
        "    return pos_tags\n",
        "\n",
        "get_position_tags(\"The cat quickly jumped over the lazy dog.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "c4fb3228-320a-4722-bbb5-d9c8098c10b9",
      "metadata": {
        "id": "c4fb3228-320a-4722-bbb5-d9c8098c10b9"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.corpus import wordnet\n",
        "import random\n",
        "\n",
        "random.seed(123)\n",
        "\n",
        "\n",
        "def synonym_replacement(text, num_replacement=2):\n",
        "\n",
        "    words = nltk.word_tokenize(text)\n",
        "\n",
        "    # 명사, 형용사 등을 태깅합니다\n",
        "    pos_tags = nltk.pos_tag(words)\n",
        "\n",
        "    # 간단한 예를 위해서 부사(RB)와 형용사(JJ)만 교체합니다\n",
        "    candidates = [word for word, pos in pos_tags if pos in ['RB', 'JJ']]\n",
        "\n",
        "    if len(candidates) < num_replacement:\n",
        "        return words\n",
        "\n",
        "    # 교체할 단어를 랜덤하게 선택합니다\n",
        "    words_to_replace = random.sample(candidates, num_replacement)\n",
        "\n",
        "\n",
        "    # 각 단어에 대해 동의어 중에 랜덤하게 하나를 선택합니다\n",
        "    for word in words_to_replace:\n",
        "        synonyms = get_synonyms(word)\n",
        "        if synonyms:\n",
        "            synonym = random.choice(synonyms)\n",
        "            text = text.replace(word, synonym, 1)\n",
        "\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "19267b15-9267-443b-a81d-fc0241eb737e",
      "metadata": {
        "id": "19267b15-9267-443b-a81d-fc0241eb737e",
        "outputId": "3c23b00c-a2c9-4a87-9a62-785dba44baf0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "The cat rapidly jumped over the work-shy dog.\n"
          ]
        }
      ],
      "source": [
        "text = \"\"\"\n",
        "The cat quickly jumped over the lazy dog.\n",
        "\"\"\"\n",
        "\n",
        "sentences = nltk.sent_tokenize(text)\n",
        "augmented_sentences = [synonym_replacement(sentence) for sentence in sentences]\n",
        "augmented_paragraph = ' '.join(augmented_sentences)\n",
        "\n",
        "print(augmented_paragraph)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e107faa-8b4c-43c2-82eb-e2d9d82eab05",
      "metadata": {
        "id": "3e107faa-8b4c-43c2-82eb-e2d9d82eab05"
      },
      "source": [
        "**원본과 증식된 텍스트 비교**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "a8773c0b-2f11-42bc-b03e-ed850b1ae9bf",
      "metadata": {
        "id": "a8773c0b-2f11-42bc-b03e-ed850b1ae9bf",
        "outputId": "6d5465bb-8c08-4b7b-f975-d5a086b51a53",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  The\n",
            "  cat\n",
            "- quickly\n",
            "+ rapidly\n",
            "  jumped\n",
            "  over\n",
            "  the\n",
            "- lazy\n",
            "+ work-shy\n",
            "  dog.\n"
          ]
        }
      ],
      "source": [
        "import difflib\n",
        "\n",
        "\n",
        "d = difflib.Differ()\n",
        "diff = d.compare(text.split(), augmented_paragraph.split())\n",
        "\n",
        "print('\\n'.join(diff))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}