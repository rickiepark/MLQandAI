{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "3c5d72f4",
      "metadata": {
        "id": "3c5d72f4"
      },
      "source": [
        "# 마지막 층만 미세 튜닝하기"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "18a56df9-d19c-4dfa-afab-097e4a57f5a1",
      "metadata": {
        "id": "18a56df9-d19c-4dfa-afab-097e4a57f5a1"
      },
      "source": [
        "이 노트북에서는 사전 훈련딘 트랜스포머의 출력 층을 미세 튜닝합니다.\n",
        "\n",
        "<img src=\"https://github.com/rickiepark/MLQandAI/blob/main/supplementary/q18-using-llms/01_classifier-finetuning/figures/2_finetune-last.png?raw=1\" width=500>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "6fd9cda8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6fd9cda8",
        "outputId": "82a8cdcf-ccde-40f3-b968-c7f68101255d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Collecting datasets\n",
            "  Downloading datasets-3.0.0-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting lightning\n",
            "  Downloading lightning-2.4.0-py3-none-any.whl.metadata (38 kB)\n",
            "Collecting watermark\n",
            "  Downloading watermark-2.4.3-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.6)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
            "Collecting pyarrow>=15.0.0 (from datasets)\n",
            "  Downloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.1.4)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.5)\n",
            "Collecting lightning-utilities<2.0,>=0.10.0 (from lightning)\n",
            "  Downloading lightning_utilities-0.11.7-py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: torch<4.0,>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (2.4.0+cu121)\n",
            "Collecting torchmetrics<3.0,>=0.7.0 (from lightning)\n",
            "  Downloading torchmetrics-1.4.2-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: typing-extensions<6.0,>=4.4.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (4.12.2)\n",
            "Collecting pytorch-lightning (from lightning)\n",
            "  Downloading pytorch_lightning-2.4.0-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: ipython>=6.0 in /usr/local/lib/python3.10/dist-packages (from watermark) (7.34.0)\n",
            "Requirement already satisfied: importlib-metadata>=1.4 in /usr/local/lib/python3.10/dist-packages (from watermark) (8.5.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from watermark) (71.0.4)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.11.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=1.4->watermark) (3.20.1)\n",
            "Collecting jedi>=0.16 (from ipython>=6.0->watermark)\n",
            "  Using cached jedi-0.19.1-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=6.0->watermark) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=6.0->watermark) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.0->watermark) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.0->watermark) (3.0.47)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=6.0->watermark) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=6.0->watermark) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=6.0->watermark) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.0->watermark) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=2.1.0->lightning) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=2.1.0->lightning) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=2.1.0->lightning) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=6.0->watermark) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=6.0->watermark) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.0->watermark) (0.2.13)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch<4.0,>=2.1.0->lightning) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch<4.0,>=2.1.0->lightning) (1.3.0)\n",
            "Downloading datasets-3.0.0-py3-none-any.whl (474 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m474.3/474.3 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning-2.4.0-py3-none-any.whl (810 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m811.0/811.0 kB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watermark-2.4.3-py2.py3-none-any.whl (7.6 kB)\n",
            "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.11.7-py3-none-any.whl (26 kB)\n",
            "Downloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (39.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchmetrics-1.4.2-py3-none-any.whl (869 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m869.2/869.2 kB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytorch_lightning-2.4.0-py3-none-any.whl (815 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m815.2/815.2 kB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "Installing collected packages: xxhash, pyarrow, lightning-utilities, jedi, dill, multiprocess, watermark, torchmetrics, pytorch-lightning, datasets, lightning\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 14.0.2\n",
            "    Uninstalling pyarrow-14.0.2:\n",
            "      Successfully uninstalled pyarrow-14.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 17.0.0 which is incompatible.\n",
            "ibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 17.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.0.0 dill-0.3.8 jedi-0.19.1 lightning-2.4.0 lightning-utilities-0.11.7 multiprocess-0.70.16 pyarrow-17.0.0 pytorch-lightning-2.4.0 torchmetrics-1.4.2 watermark-2.4.3 xxhash-3.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers datasets lightning watermark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/rickiepark/MLQandAI/main/supplementary/q18-using-llms/01_classifier-finetuning/local_dataset_utilities.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CAbnGz6rkJvV",
        "outputId": "33d3a365-a110-4bdd-a374-bb6d12eae6b3"
      },
      "id": "CAbnGz6rkJvV",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-09-15 02:49:03--  https://raw.githubusercontent.com/rickiepark/MLQandAI/main/supplementary/q18-using-llms/01_classifier-finetuning/local_dataset_utilities.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2949 (2.9K) [text/plain]\n",
            "Saving to: ‘local_dataset_utilities.py’\n",
            "\n",
            "\r          local_dat   0%[                    ]       0  --.-KB/s               \rlocal_dataset_utili 100%[===================>]   2.88K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-09-15 02:49:03 (54.3 MB/s) - ‘local_dataset_utilities.py’ saved [2949/2949]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "033b75c5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "033b75c5",
        "outputId": "d8cc75ab-6c83-43ec-8333-f02cf713c173"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch       : 2.4.0+cu121\n",
            "transformers: 4.44.2\n",
            "datasets    : 3.0.0\n",
            "lightning   : 2.4.0\n",
            "\n",
            "conda environment: n/a\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%load_ext watermark\n",
        "%watermark --conda -p torch,transformers,datasets,lightning"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "59e5aefc-40b8-4361-bc2a-6e12d25235d6",
      "metadata": {
        "tags": [],
        "id": "59e5aefc-40b8-4361-bc2a-6e12d25235d6"
      },
      "source": [
        "# 1 데이터셋을 데이터프레임으로 로드하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "e39e2228-5f0b-4fb9-b762-df26c2052b45",
      "metadata": {
        "id": "e39e2228-5f0b-4fb9-b762-df26c2052b45"
      },
      "outputs": [],
      "source": [
        "import os.path as op\n",
        "\n",
        "from datasets import load_dataset\n",
        "\n",
        "import lightning as L\n",
        "from lightning.pytorch.loggers import CSVLogger\n",
        "from lightning.pytorch.callbacks import ModelCheckpoint\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "from local_dataset_utilities import download_dataset, load_dataset_into_to_dataframe, partition_dataset\n",
        "from local_dataset_utilities import IMDBDataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "fb31ac90-9e3a-41d0-baf1-8e613043924b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "id": "fb31ac90-9e3a-41d0-baf1-8e613043924b",
        "outputId": "109797e6-f8ba-4d6c-eb34-b476ef285c1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100% | 80.23 MB | 2.43 MB/s | 33.01 sec elapsed"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 21%|██        | 10378/50000 [00:09<00:35, 1122.75it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-70fa491b875c>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdownload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_dataset_into_to_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mpartition_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/local_dataset_utilities.py\u001b[0m in \u001b[0;36mload_dataset_into_to_dataframe\u001b[0;34m()\u001b[0m\n\u001b[1;32m     64\u001b[0m                             \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtxt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"review\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"sentiment\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m                         )\n\u001b[0;32m---> 66\u001b[0;31m                         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0mcopy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m     op = _Concatenator(\n\u001b[0m\u001b[1;32m    381\u001b[0m         \u001b[0mobjs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0msort\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m     ) -> None:\n\u001b[0;32m--> 416\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mABCSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCDataFrame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m             raise TypeError(\n\u001b[1;32m    418\u001b[0m                 \u001b[0;34m\"first argument must be an iterable of pandas \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/dtypes/generic.py\u001b[0m in \u001b[0;36m_instancecheck\u001b[0;34m(cls, inst)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;31m# https://github.com/python/mypy/issues/1006\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;31m# error: 'classmethod' used with a non-method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_instancecheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minst\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minst\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "download_dataset()\n",
        "\n",
        "df = load_dataset_into_to_dataframe()\n",
        "partition_dataset(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "221f30a1-b433-4304-a18d-8d03abd42b58",
      "metadata": {
        "id": "221f30a1-b433-4304-a18d-8d03abd42b58"
      },
      "outputs": [],
      "source": [
        "df_train = pd.read_csv(\"train.csv\")\n",
        "df_val = pd.read_csv(\"val.csv\")\n",
        "df_test = pd.read_csv(\"test.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "846d83b1",
      "metadata": {
        "id": "846d83b1"
      },
      "source": [
        "# 2 토큰화"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2bd5f770",
      "metadata": {
        "id": "2bd5f770"
      },
      "source": [
        "**`load_dataset`으로 데이터셋 로드하기**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1aa66c7",
      "metadata": {
        "id": "a1aa66c7"
      },
      "outputs": [],
      "source": [
        "imdb_dataset = load_dataset(\n",
        "    \"csv\",\n",
        "    data_files={\n",
        "        \"train\": \"train.csv\",\n",
        "        \"validation\": \"val.csv\",\n",
        "        \"test\": \"test.csv\",\n",
        "    },\n",
        ")\n",
        "\n",
        "print(imdb_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "029adc8f-cdfe-4386-9552-a1120f49adee",
      "metadata": {
        "id": "029adc8f-cdfe-4386-9552-a1120f49adee"
      },
      "source": [
        "**데이터셋 토큰화하기**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ea762ba",
      "metadata": {
        "id": "5ea762ba"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "print(\"토크나이저의 입력 최대 길이:\", tokenizer.model_max_length)\n",
        "print(\"토크나이저의 어휘 사전 크기:\", tokenizer.vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8432c15c",
      "metadata": {
        "id": "8432c15c"
      },
      "outputs": [],
      "source": [
        "def tokenize_text(batch):\n",
        "    return tokenizer(batch[\"text\"], truncation=True, padding=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0bb392cf",
      "metadata": {
        "id": "0bb392cf"
      },
      "outputs": [],
      "source": [
        "imdb_tokenized = imdb_dataset.map(tokenize_text, batched=True, batch_size=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d4103c3",
      "metadata": {
        "id": "6d4103c3"
      },
      "outputs": [],
      "source": [
        "del imdb_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89ef894c-978f-47f2-9d61-cb6a9f38e745",
      "metadata": {
        "id": "89ef894c-978f-47f2-9d61-cb6a9f38e745"
      },
      "outputs": [],
      "source": [
        "imdb_tokenized.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ea67091-aeb7-46c1-871f-638ce58d8a0e",
      "metadata": {
        "id": "0ea67091-aeb7-46c1-871f-638ce58d8a0e"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4c4f8cd8-e641-45fb-9893-70677631917a",
      "metadata": {
        "id": "4c4f8cd8-e641-45fb-9893-70677631917a"
      },
      "source": [
        "# 3 DataLoader 설정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0807b068-7d8f-4055-a26a-177e07dea4c7",
      "metadata": {
        "id": "0807b068-7d8f-4055-a26a-177e07dea4c7"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "\n",
        "class IMDBDataset(Dataset):\n",
        "    def __init__(self, dataset_dict, partition_key=\"train\"):\n",
        "        self.partition = dataset_dict[partition_key]\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.partition[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.partition.num_rows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "90cb08f3-ef77-4351-8b19-42d99dd24f98",
      "metadata": {
        "id": "90cb08f3-ef77-4351-8b19-42d99dd24f98"
      },
      "outputs": [],
      "source": [
        "train_dataset = IMDBDataset(imdb_tokenized, partition_key=\"train\")\n",
        "val_dataset = IMDBDataset(imdb_tokenized, partition_key=\"validation\")\n",
        "test_dataset = IMDBDataset(imdb_tokenized, partition_key=\"test\")\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    dataset=train_dataset,\n",
        "    batch_size=12,\n",
        "    shuffle=True,\n",
        "    num_workers=4\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    dataset=val_dataset,\n",
        "    batch_size=12,\n",
        "    num_workers=4\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    dataset=test_dataset,\n",
        "    batch_size=12,\n",
        "    num_workers=4\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c977b07-2559-4ff7-85c4-d62785e81558",
      "metadata": {
        "id": "6c977b07-2559-4ff7-85c4-d62785e81558"
      },
      "source": [
        "# 4 DistilBERT 초기화"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10b1e449-7e00-4965-9883-f97374503996",
      "metadata": {
        "id": "10b1e449-7e00-4965-9883-f97374503996"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    \"distilbert-base-uncased\", num_labels=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e9854e27-fc4f-418e-996f-a8ef04a295ac",
      "metadata": {
        "id": "e9854e27-fc4f-418e-996f-a8ef04a295ac"
      },
      "source": [
        "**모든 층 동결**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c14e61f3-3279-4725-ad7a-3c77f85aa39d",
      "metadata": {
        "id": "c14e61f3-3279-4725-ad7a-3c77f85aa39d"
      },
      "outputs": [],
      "source": [
        "for param in model.parameters():\n",
        "    param.requires_grad = False"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a6d3e532-3684-4dbf-a8ce-60b6c6675a00",
      "metadata": {
        "id": "a6d3e532-3684-4dbf-a8ce-60b6c6675a00"
      },
      "source": [
        "**마지막 층 동결해제**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1bca22b5-8a48-4006-929f-66734a745a50",
      "metadata": {
        "id": "1bca22b5-8a48-4006-929f-66734a745a50"
      },
      "outputs": [],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f852fc6-3b00-4831-a973-e03b539a6cd0",
      "metadata": {
        "id": "4f852fc6-3b00-4831-a973-e03b539a6cd0"
      },
      "outputs": [],
      "source": [
        "for param in model.pre_classifier.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "for param in model.classifier.parameters():\n",
        "    param.requires_grad = True"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "83971bc4-143d-4d82-b5cb-8774f9112f53",
      "metadata": {
        "id": "83971bc4-143d-4d82-b5cb-8774f9112f53"
      },
      "source": [
        "# 5 미세 튜닝"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "730b9a87-709e-4f3d-9c9f-475ccbb56908",
      "metadata": {
        "id": "730b9a87-709e-4f3d-9c9f-475ccbb56908"
      },
      "source": [
        "**훈련을 위해 LightningModule로 감싸기**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f2c474d",
      "metadata": {
        "id": "9f2c474d"
      },
      "outputs": [],
      "source": [
        "import lightning as L\n",
        "import torch\n",
        "import torchmetrics\n",
        "\n",
        "\n",
        "class CustomLightningModule(L.LightningModule):\n",
        "    def __init__(self, model, learning_rate=5e-5):\n",
        "        super().__init__()\n",
        "\n",
        "        self.learning_rate = learning_rate\n",
        "        self.model = model\n",
        "\n",
        "        self.val_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=2)\n",
        "        self.test_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=2)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, labels):\n",
        "        return self.model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        outputs = self(batch[\"input_ids\"], attention_mask=batch[\"attention_mask\"],\n",
        "                       labels=batch[\"label\"])\n",
        "        self.log(\"train_loss\", outputs[\"loss\"])\n",
        "        return outputs[\"loss\"]  # this is passed to the optimizer for training\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        outputs = self(batch[\"input_ids\"], attention_mask=batch[\"attention_mask\"],\n",
        "                       labels=batch[\"label\"])\n",
        "        self.log(\"val_loss\", outputs[\"loss\"], prog_bar=True)\n",
        "\n",
        "        logits = outputs[\"logits\"]\n",
        "        predicted_labels = torch.argmax(logits, 1)\n",
        "        self.val_acc(predicted_labels, batch[\"label\"])\n",
        "        self.log(\"val_acc\", self.val_acc, prog_bar=True)\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        outputs = self(batch[\"input_ids\"], attention_mask=batch[\"attention_mask\"],\n",
        "                       labels=batch[\"label\"])\n",
        "\n",
        "        logits = outputs[\"logits\"]\n",
        "        predicted_labels = torch.argmax(logits, 1)\n",
        "        self.test_acc(predicted_labels, batch[\"label\"])\n",
        "        self.log(\"accuracy\", self.test_acc, prog_bar=True)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
        "        return optimizer\n",
        "\n",
        "\n",
        "lightning_model = CustomLightningModule(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e6dab813-e1fc-47cd-87a1-5eb8070699c6",
      "metadata": {
        "id": "e6dab813-e1fc-47cd-87a1-5eb8070699c6"
      },
      "outputs": [],
      "source": [
        "from lightning.pytorch.callbacks import ModelCheckpoint\n",
        "from lightning.pytorch.loggers import CSVLogger\n",
        "\n",
        "\n",
        "callbacks = [\n",
        "    ModelCheckpoint(\n",
        "        save_top_k=1, mode=\"max\", monitor=\"val_acc\"\n",
        "    )  # 최상위 1개 모델 저장하기\n",
        "]\n",
        "logger = CSVLogger(save_dir=\"logs/\", name=\"my-model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "492aa043-02da-459e-a266-091b34254ac6",
      "metadata": {
        "id": "492aa043-02da-459e-a266-091b34254ac6"
      },
      "outputs": [],
      "source": [
        "trainer = L.Trainer(\n",
        "    max_epochs=3,\n",
        "    callbacks=callbacks,\n",
        "    accelerator=\"gpu\",\n",
        "    precision=\"16-mixed\",\n",
        "    devices=[1],\n",
        "    logger=logger,\n",
        "    log_every_n_steps=10,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff08ea9a-faf6-410d-9a2f-a0d2b92dd027",
      "metadata": {
        "id": "ff08ea9a-faf6-410d-9a2f-a0d2b92dd027"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "start = time.time()\n",
        "\n",
        "trainer.fit(model=lightning_model,\n",
        "            train_dataloaders=train_loader,\n",
        "            val_dataloaders=val_loader)\n",
        "\n",
        "end = time.time()\n",
        "elapsed = end - start\n",
        "print(f\"소요 시간 {elapsed/60:.2f} min\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d795778a-70d2-4b04-96fb-598eccbcd1be",
      "metadata": {
        "id": "d795778a-70d2-4b04-96fb-598eccbcd1be"
      },
      "outputs": [],
      "source": [
        "trainer.test(lightning_model, dataloaders=train_loader, ckpt_path=\"best\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10ca0af1-106e-4ef7-9793-478d580af827",
      "metadata": {
        "id": "10ca0af1-106e-4ef7-9793-478d580af827"
      },
      "outputs": [],
      "source": [
        "trainer.test(lightning_model, dataloaders=val_loader, ckpt_path=\"best\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eeb92de4-d483-4627-b9f3-f0bba0cddd9c",
      "metadata": {
        "id": "eeb92de4-d483-4627-b9f3-f0bba0cddd9c"
      },
      "outputs": [],
      "source": [
        "trainer.test(lightning_model, dataloaders=test_loader, ckpt_path=\"best\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}